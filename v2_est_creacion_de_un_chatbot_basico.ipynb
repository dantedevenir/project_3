{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OL9isTPfrOY_"
      },
      "source": [
        "# Chatbot para que me proponga que cenar\n",
        "\n",
        "\n",
        "## Introducción\n",
        "\n",
        "En este proyecto, se propone desarrollar un chatbot basado en el uso de una red neuronal para clasificar intents. El objetivo principal es crear un asistente conversacional capaz de interactuar con los usuarios y responder a sus solicitudes de manera adecuada. Para lograr esto, se utilizará un enfoque basado en machine learning, específicamente una red neuronal alimentada con un conjunto de datos etiquetados que describen diversos intents y patrones de conversación.\n",
        "\n",
        "El chatbot se entrenará utilizando un archivo de configuración en formato JSON, que contiene un diccionario de intents. Cada intent incluye un conjunto de frases de ejemplo que representan las posibles entradas del usuario, así como una lista de respuestas predefinidas que el chatbot proporcionará al identificar dicho intent. Estos datos serán preprocesados y convertidos en una representación numérica que permita a la red neuronal aprender a clasificar correctamente los intents en función de las entradas del usuario.\n",
        "\n",
        "El modelo entrenado será capaz de identificar el intent del usuario a partir de su mensaje y seleccionar una respuesta adecuada de las respuestas predefinidas asociadas.\n",
        "\n",
        "El enfoque basado en el uso de redes neuronales para la clasificación de intents permite que el chatbot sea adaptable y escalable. A medida que se agreguen más intents o se modifiquen los existentes, el modelo se puede volver a entrenar para mejorar la precisión y la variedad de respuestas, proporcionando una experiencia más enriquecedora al usuario.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InjCViSJvnrs"
      },
      "outputs": [],
      "source": [
        "!pip install unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZ5xF8uZpB7O"
      },
      "outputs": [],
      "source": [
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "!pip install spacy textblob unidecode\n",
        "!python -m spacy download es_core_news_sm\n",
        "!python -m textblob.download_corpora\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeTuYdZI3x0y"
      },
      "outputs": [],
      "source": [
        "\n",
        "nltk.download('stopwords', download_dir='nltk_data/')\n",
        "nltk.download('punkt', download_dir='nltk_data/')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clhk_IT0nYqT"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import tensorflow as tf\n",
        "import unidecode\n",
        "\n",
        "# Importar bibliotecas necesarias\n",
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import unidecode\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kb3BvlLcnmZO"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Cargar el archivo JSON\n",
        "with open('intents.json', 'r', encoding='utf-8') as file:\n",
        "    intents = json.load(file)\n",
        "\n",
        "# Verificar el contenido del archivo\n",
        "print(intents)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyexODfGszYE"
      },
      "source": [
        "La estructura del archivo JSON `intents` se organiza en forma de un diccionario que contiene una lista de \"intents\". Cada intent es un objeto que incluye tres elementos principales:\n",
        "\n",
        "1. **`tag`**: Una etiqueta que identifica el nombre o categoría del intent. Sirve como identificador único para el intent.\n",
        "\n",
        "2. **`patterns`**: Una lista de frases de ejemplo que representan posibles entradas del usuario. Estas frases son variaciones de lo que el usuario podría decir para expresar ese intent.\n",
        "\n",
        "3. **`responses`**: Una lista de respuestas predefinidas que el chatbot puede utilizar cuando se detecta este intent. El chatbot seleccionará aleatoriamente una de estas respuestas para proporcionar una respuesta coherente al usuario.\n",
        "\n",
        "### Ejemplo de la Estructura de `intents.json`\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"intents\": [\n",
        "    {\n",
        "      \"tag\": \"saludo\",\n",
        "      \"patterns\": [\n",
        "        \"Hola\",\n",
        "        \"Buenos días\",\n",
        "        \"¿Qué tal?\",\n",
        "        \"¿Cómo estás?\",\n",
        "        \"Hola, ¿qué tal?\"\n",
        "      ],\n",
        "      \"responses\": [\n",
        "        \"¡Hola! ¿En qué puedo ayudarte?\",\n",
        "        \"¡Buenos días! ¿Cómo te puedo ayudar?\",\n",
        "        \"Hola, ¿en qué puedo asistirte?\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"despedida\",\n",
        "      \"patterns\": [\n",
        "        \"Adiós\",\n",
        "        \"Hasta luego\",\n",
        "        \"Nos vemos\",\n",
        "        \"Chao\",\n",
        "        \"Me tengo que ir\"\n",
        "      ],\n",
        "      \"responses\": [\n",
        "        \"¡Adiós! Que tengas un buen día.\",\n",
        "        \"Hasta luego, cuídate.\",\n",
        "        \"Nos vemos pronto.\"\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n",
        "En este ejemplo:\n",
        "- Hay dos intents: \"saludo\" y \"despedida\".\n",
        "- Cada intent tiene varias frases de ejemplo en `patterns` que el usuario podría decir.\n",
        "- Las respuestas posibles se encuentran en `responses` y se elige una al azar cuando el intent se detecta.\n",
        "\n",
        "Esta estructura permite que el chatbot reconozca diferentes intents basados en la entrada del usuario y responda adecuadamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEF2qhMOpXdZ"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import unidecode\n",
        "from nltk.corpus import stopwords\n",
        "from textblob import TextBlob\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Cargar el modelo de spaCy para español\n",
        "nlp = spacy.load('es_core_news_sm')\n",
        "\n",
        "# Cargar stop words en español\n",
        "stop_words = set(stopwords.words('spanish'))\n",
        "\n",
        "# Función para preprocesar el texto\n",
        "def preprocess_text(text):\n",
        "    # Quitar las tildes y convertir a minúsculas\n",
        "    text = unidecode.unidecode(text.lower())\n",
        "\n",
        "    # Corrección ortográfica usando TextBlob\n",
        "    corrected_text = str(TextBlob(text).correct())\n",
        "\n",
        "    # Tokenizar y lematizar usando spaCy\n",
        "    doc = nlp(corrected_text)\n",
        "\n",
        "    # Filtrar stop words, signos de puntuación y lematizar\n",
        "    processed_words = [\n",
        "        token.lemma_ for token in doc\n",
        "        if token.text not in stop_words and not token.is_punct and not token.is_digit\n",
        "    ]\n",
        "\n",
        "    return ' '.join(processed_words)\n",
        "\n",
        "# Paso 5: Preprocesar los patrones y las etiquetas\n",
        "patterns = []\n",
        "tags = []\n",
        "\n",
        "for intent in intents[\"intents\"]:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        processed_pattern = preprocess_text(pattern)\n",
        "        patterns.append(processed_pattern)\n",
        "        tags.append(intent[\"tag\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEw2XXVHphr2"
      },
      "outputs": [],
      "source": [
        "# Paso 6: Convertir los patrones en características utilizando CountVectorizer\n",
        "vectorizer = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\n",
        "X = vectorizer.fit_transform(patterns).toarray()\n",
        "\n",
        "# Convertir las etiquetas en números utilizando LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(tags)\n",
        "\n",
        "# Dividir los datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhovUSORtC1l"
      },
      "source": [
        "A continuación, vamos a crear una red neuronal densa para entrenarla utilizando los intents definidos en el archivo JSON. La red neuronal será capaz de aprender a clasificar las entradas del usuario en los diferentes intents, basándose en los ejemplos de frases proporcionados. Este modelo nos permitirá identificar el intent correcto y proporcionar una respuesta adecuada según las respuestas predefinidas asociadas a cada intent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDAUzmFKpmVE"
      },
      "outputs": [],
      "source": [
        "# Paso 7: Crear el modelo de red neuronal\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(X_train.shape[1],), activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(set(tags)), activation=\"softmax\"))\n",
        "\n",
        "# Compilar el modelo\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOjm8q-xuEyD"
      },
      "source": [
        "### Ejercicio\n",
        "¿Creen que mejorarán las predicciones del chatbot si agregamos una capa recurrente?\n",
        "___\n",
        "Responder acá:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzIA8Jntpqu7"
      },
      "outputs": [],
      "source": [
        "# Entrenar el modelo\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=4, verbose=1, validation_data=(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jV3RHgSjp5GC"
      },
      "outputs": [],
      "source": [
        "# Guardar el modelo y el vectorizador\n",
        "model.save(\"chatbot_model.h5\")\n",
        "np.save(\"classes.npy\", label_encoder.classes_)\n",
        "np.save(\"vectorizer.npy\", vectorizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzO0w0dIsNZy"
      },
      "source": [
        " Los archivos se guardan de forma temporal en la raíz del entorno, es decir, en el directorio principal (`/content/`).\n",
        "\n",
        "En este caso, los archivos se guardarán en:\n",
        "\n",
        "- `/content/chatbot_model.h5`\n",
        "- `/content/classes.npy`\n",
        "- `/content/vectorizer.npy`\n",
        "\n",
        "Tenga en cuenta que es de forma temporal, es decir si se reinicia el entorno estos se borran..\n",
        "\n",
        "#### Cómo Descargar los Archivos Desde Colab\n",
        "\n",
        "Puedes descargar los archivos a tu computadora con las siguientes líneas de código:\n",
        "\n",
        "```python\n",
        "from google.colab import files\n",
        "\n",
        "# Descargar el modelo y los archivos relacionados\n",
        "files.download(\"chatbot_model.h5\")\n",
        "files.download(\"classes.npy\")\n",
        "files.download(\"vectorizer.npy\")\n",
        "```\n",
        "\n",
        "#### Guardar los Archivos en Google Drive\n",
        "\n",
        "También puedes montar tu Google Drive y guardar los archivos allí para que permanezcan disponibles:\n",
        "\n",
        "```python\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Guardar los archivos en una carpeta de Google Drive\n",
        "model.save('/content/drive/MyDrive/chatbot_model.h5')\n",
        "np.save('/content/drive/MyDrive/classes.npy', label_encoder.classes_)\n",
        "np.save('/content/drive/MyDrive/vectorizer.npy', vectorizer)\n",
        "```\n",
        "\n",
        "De esta forma, los archivos se guardarán en tu Google Drive y estarán disponibles incluso después de cerrar la sesión en Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgiBfVmMp_lg"
      },
      "outputs": [],
      "source": [
        "def chatbot_response(user_input):\n",
        "    # Convertir la entrada del usuario en un formato que el modelo pueda usar\n",
        "    input_data = vectorizer.transform([preprocess_text(user_input)]).toarray()\n",
        "    prediction = model.predict(input_data)\n",
        "\n",
        "    # Obtener la probabilidad más alta y su índice\n",
        "\n",
        "    intent_index = np.argmax(prediction)\n",
        "    max_prob = prediction[0][intent_index]  # Obtener la probabilidad más alta\n",
        "    print(f\"Probabilidad de la predicción: {max_prob:.2f}\")\n",
        "    # Definir un umbral de confianza\n",
        "    confidence_threshold = 0.8  # 70% de confianza\n",
        "\n",
        "    # Si la probabilidad es mayor que el umbral, devolver el intent; si no, pedir que repita la pregunta\n",
        "    if max_prob >= confidence_threshold:\n",
        "        intent_tag = label_encoder.inverse_transform([intent_index])[0]\n",
        "\n",
        "        # Buscar una respuesta aleatoria para el intent predicho\n",
        "        for intent in intents[\"intents\"]:\n",
        "            if intent[\"tag\"] == intent_tag:\n",
        "                response = random.choice(intent[\"responses\"])\n",
        "                break\n",
        "    else:\n",
        "        # Si la confianza es baja, pedir que repita la pregunta\n",
        "        response = \"No estoy seguro de haber entendido. ¿Podrías repetir la pregunta?\"\n",
        "\n",
        "    return response\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gQF4vgqSTSh"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Bucle de interacción del Chatbot\n",
        "print(\"¡Hola! Soy un chatbot. ¿En qué puedo ayudarte? (Escribe 'salir' para terminar)\")\n",
        "while True:\n",
        "    user_input = input(\"Tú: \")\n",
        "    if user_input.lower() == \"salir\":\n",
        "        print(\"Chatbot: ¡Hasta luego!\")\n",
        "        break\n",
        "    response = chatbot_response(user_input)\n",
        "    print(\"Chatbot:\", response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al8R2cb3uVMu"
      },
      "source": [
        "### Ejercicio:\n",
        "Si prueban el chatbot y le preguntan \"¿Qué otra opción hay?\", notarán que no responde de forma correcta. Para solucionar esto, agreguen un nuevo intent en el archivo `intents.json` que maneje este tipo de solicitud, de modo que el chatbot pueda reconocerlo y responder adecuadamente. Agregar que si no entiende (o no encuentra la pregunta) responda \"Repite la pregunta\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nyrg441AIr5z"
      },
      "source": [
        "Como última modificación a nuestro chatbot, vamos a agregarle la opción de que nos pregunte si preferimos una opción vegetariana o con carne cuando estemos buscando recomendaciones de comida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKccMzT7xHAo"
      },
      "outputs": [],
      "source": [
        "preferencia = None  # Variable global para almacenar la preferencia del usuario\n",
        "ultima_opcion = None  # Variable para recordar el último intent de cena\n",
        "\n",
        "def chatbot_response1(user_input):\n",
        "    global preferencia, ultima_opcion\n",
        "\n",
        "    # Convertir la entrada del usuario en un formato que el modelo pueda usar\n",
        "    input_data = vectorizer.transform([preprocess_text(user_input)]).toarray()\n",
        "    prediction = model.predict(input_data)\n",
        "\n",
        "    # Obtener la probabilidad más alta y su índice\n",
        "    intent_index = np.argmax(prediction)\n",
        "    max_prob = prediction[0][intent_index]  # Obtener la probabilidad más alta\n",
        "    print(f\"Probabilidad de la predicción: {max_prob:.2f}\")\n",
        "\n",
        "    # Definir un umbral de confianza\n",
        "    confidence_threshold = 0.8  # 80% de confianza\n",
        "\n",
        "    # Si la probabilidad es mayor que el umbral, devolver el intent\n",
        "    if max_prob >= confidence_threshold:\n",
        "        intent_tag = label_encoder.inverse_transform([intent_index])[0]\n",
        "\n",
        "        # Si el intent es \"cena\" y aún no tenemos una preferencia, preguntar sobre la preferencia\n",
        "        if intent_tag == \"cena\" and preferencia is None:\n",
        "            preferencia = \"preguntada\"\n",
        "            return \"¿Prefieres una opción con carne o vegetariana?\"\n",
        "\n",
        "        # Si el intent es \"otra_opcion\", ofrecer otra opción basada en la preferencia ya seleccionada\n",
        "        if intent_tag == \"otra_opcion\" and preferencia is not None:\n",
        "            intent_tag = ultima_opcion  # Mantener la última preferencia de cena (carne o vegetariana)\n",
        "\n",
        "        # Si el intent es de despedida o agradecimiento, restablecer la preferencia\n",
        "        if intent_tag in [\"despedida\", \"agradecimiento\"]:\n",
        "            preferencia = None  # Reiniciar la preferencia\n",
        "            for intent in intents[\"intents\"]:\n",
        "                if intent[\"tag\"] == intent_tag:\n",
        "                    response = random.choice(intent[\"responses\"])\n",
        "                    return response\n",
        "\n",
        "    # Si el chatbot ya preguntó sobre las preferencias\n",
        "    if preferencia == \"preguntada\":\n",
        "        if \"carne\" in user_input.lower():\n",
        "            preferencia = \"carne\"\n",
        "            intent_tag = \"cena_carne\"\n",
        "        elif \"vegetariana\" in user_input.lower():\n",
        "            preferencia = \"vegetariana\"\n",
        "            intent_tag = \"cena_vegetariana\"\n",
        "        else:\n",
        "            return \"Lo siento, no entendí tu preferencia. ¿Carne o vegetariana?\"\n",
        "\n",
        "    # Buscar una respuesta aleatoria para el intent predicho\n",
        "    for intent in intents[\"intents\"]:\n",
        "        if intent[\"tag\"] == intent_tag:\n",
        "            response = random.choice(intent[\"responses\"])\n",
        "            break\n",
        "\n",
        "    # Guardar el intent actual como la última opción seleccionada (carne o vegetariana)\n",
        "    if intent_tag in [\"cena_carne\", \"cena_vegetariana\"]:\n",
        "        ultima_opcion = intent_tag  # Mantener la preferencia para \"otra opción\"\n",
        "\n",
        "    return response\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gu48ltPOxM4o"
      },
      "outputs": [],
      "source": [
        "print(\"¡Hola! Soy un chatbot con memoria. ¿En qué puedo ayudarte? (Escribe 'salir' para terminar)\")\n",
        "while True:\n",
        "    user_input = input(\"Tú: \")\n",
        "    if user_input.lower() == \"salir\":\n",
        "        print(\"Chatbot: ¡Hasta luego!\")\n",
        "        break\n",
        "    response = chatbot_response1(user_input)\n",
        "    print(\"Chatbot:\", response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "Y7FawJVNkllO",
        "outputId": "be1715c7-c288-4cf3-aca5-cd1673615ef2"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"chatbot_model.h5\")\n",
        "files.download(\"classes.npy\")\n",
        "files.download(\"vectorizer.npy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVtz7HzDSLsP"
      },
      "source": [
        "____\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "history_visible": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
