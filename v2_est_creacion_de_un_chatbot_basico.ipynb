{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OL9isTPfrOY_"
      },
      "source": [
        "# Chatbot para que me proponga que cenar\n",
        "\n",
        "\n",
        "## Introducción\n",
        "\n",
        "En este proyecto, se propone desarrollar un chatbot basado en el uso de una red neuronal para clasificar intents. El objetivo principal es crear un asistente conversacional capaz de interactuar con los usuarios y responder a sus solicitudes de manera adecuada. Para lograr esto, se utilizará un enfoque basado en machine learning, específicamente una red neuronal alimentada con un conjunto de datos etiquetados que describen diversos intents y patrones de conversación.\n",
        "\n",
        "El chatbot se entrenará utilizando un archivo de configuración en formato JSON, que contiene un diccionario de intents. Cada intent incluye un conjunto de frases de ejemplo que representan las posibles entradas del usuario, así como una lista de respuestas predefinidas que el chatbot proporcionará al identificar dicho intent. Estos datos serán preprocesados y convertidos en una representación numérica que permita a la red neuronal aprender a clasificar correctamente los intents en función de las entradas del usuario.\n",
        "\n",
        "El modelo entrenado será capaz de identificar el intent del usuario a partir de su mensaje y seleccionar una respuesta adecuada de las respuestas predefinidas asociadas.\n",
        "\n",
        "El enfoque basado en el uso de redes neuronales para la clasificación de intents permite que el chatbot sea adaptable y escalable. A medida que se agreguen más intents o se modifiquen los existentes, el modelo se puede volver a entrenar para mejorar la precisión y la variedad de respuestas, proporcionando una experiencia más enriquecedora al usuario.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mZ5xF8uZpB7O"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/dandev/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /home/dandev/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /home/dandev/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GeTuYdZI3x0y"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to nltk_data/...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to nltk_data/...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "nltk.download('stopwords', download_dir='nltk_data/')\n",
        "nltk.download('punkt', download_dir='nltk_data/')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "clhk_IT0nYqT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-15 21:43:57.180905: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-10-15 21:43:57.243423: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-10-15 21:43:57.246127: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-10-15 21:43:58.408646: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import tensorflow as tf\n",
        "import unidecode\n",
        "\n",
        "# Importar bibliotecas necesarias\n",
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import unidecode\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Kb3BvlLcnmZO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'intents': [{'tag': 'saludo', 'patterns': ['Hola', 'Buenos días', '¿Qué tal?', '¿Cómo estás?', 'Hola, ¿qué tal?', '¡Hola!', 'Buenas', 'Hola, ¿cómo te va?', 'Saludos', 'Hola, ¿cómo te encuentras?', '¿Qué hay de nuevo?', 'Hola, mucho gusto', 'Buenas tardes', 'Hola, buen día', '¿Qué cuentas?'], 'responses': ['¡Hola! ¿En qué puedo ayudarte?', '¡Buenos días! ¿Cómo te puedo ayudar?', 'Hola, ¿en qué puedo asistirte?']}, {'tag': 'despedida', 'patterns': ['Adiós', 'Hasta luego', 'Nos vemos', 'Chao', 'Me tengo que ir', 'Hasta pronto', 'Cuídate', 'Nos vemos luego', 'Me voy', 'Que tengas un buen día', 'Hasta la próxima', 'Nos vemos más tarde', 'Adiós, que estés bien', 'Me despido', 'Que te vaya bien'], 'responses': ['¡Adiós! Que tengas un buen día.', 'Hasta luego, cuídate.', 'Nos vemos pronto.']}, {'tag': 'opcion', 'patterns': ['opción', 'Tienes otra opción', 'No me gusta tu sugerencia', 'otra cosa', 'tienes otra comida', '¿Qué otra opción hay?', '¿Puedes darme otra opción?', 'Dame otra sugerencia', 'No estoy convencido, otra opción', '¿Qué más tienes?', 'Otra alternativa, por favor', 'No me gusta, ¿qué más puedes ofrecer?', 'Sugiéreme otra cosa', '¿Alguna otra recomendación?', 'Algo más, por favor', 'Quiero una alternativa'], 'responses': ['Otra opción podría ser preparar tacos vegetarianos con frijoles y aguacate.', '¿Qué tal una sopa de tomate y albahaca con un toque de crema?', 'También podrías probar un risotto de setas y parmesano.', 'Una tortilla de patatas con cebolla caramelizada podría ser una opción interesante.', 'Ensalada César con pollo a la parrilla.', 'Sándwich de pavo con queso suizo y mostaza.', 'Pizza de verduras asadas con queso de cabra.', 'Sopa de calabaza y zanahoria con pan crujiente.', 'Pasta con salsa de champiñones y espinacas.', 'Tortitas de garbanzos con ensalada de rúcula.', 'Papas rellenas con brócoli y queso cheddar.', 'Enchiladas de pollo con salsa verde.', 'Bowl de quinoa con hummus y vegetales asados.', 'Curry de garbanzos y espinacas con arroz basmati.']}, {'tag': 'agradecimiento', 'patterns': ['Gracias', 'Muchas gracias', 'Te lo agradezco', 'Gracias por la ayuda', 'Buena opción', 'Me gusta esa opción', 'Esa opción suena bien', 'Suena delicioso', 'Qué buena sugerencia', 'Me encanta esa idea', 'Esa opción está genial', 'Gracias, suena muy bien', 'Qué buena opción para cenar', 'Parece delicioso', 'Me encanta la sugerencia'], 'responses': ['¡De nada! Siempre estoy aquí para ayudarte.', 'Es un placer ayudarte.', '¡Con gusto!']}, {'tag': 'cena', 'patterns': ['¿Qué podría cenar hoy?', '¿Tienes alguna sugerencia para la cena?', 'Estoy buscando ideas para cenar', 'Quiero preparar algo para cenar', 'No sé qué cenar hoy', '¿Qué me recomiendas para cenar?', '¿Qué puedo cocinar esta noche?', 'Dame una idea para la cena', 'Estoy pensando en qué cenar', 'Sugiéreme algo para la cena', '¿Tienes alguna idea para la cena?', 'No sé qué hacer de cenar', '¿Qué podría cocinar esta noche?', 'Necesito ideas para la cena', '¿Alguna recomendación para cenar?', '¿Qué comer hoy?', 'Tengo hambre y no sé qué comer', 'que opcion de cena me podrias dar?'], 'responses': ['Ensalada de pollo con aguacate y aderezo de mostaza.', 'Lasaña de verduras con queso ricotta.', 'Filete de atún a la parrilla con espárragos.', 'Sopa de lentejas con pan integral tostado.', 'Wraps de pollo al pesto con vegetales asados.', 'Arroz con mariscos y un toque de limón.', 'Quiche de espinacas y queso feta.', 'Hamburguesa de garbanzos con guacamole.', 'Tacos de pescado con col y salsa de mango.', 'Pechuga de pollo a la plancha con puré de batata.']}, {'tag': 'cena_carne', 'patterns': ['Quiero una opción con carne', 'Prefiero carne', 'Me gusta la carne', 'Algo con carne estaría bien'], 'responses': ['Podrías preparar un filete de res con puré de papas.', '¿Qué tal un pollo a la parrilla con ensalada?', 'Unos tacos de carne asada siempre son una buena opción.', 'Podrías hacer unas albóndigas con salsa de tomate.']}, {'tag': 'cena_vegetariana', 'patterns': ['Quiero una opción vegetariana', 'Prefiero algo sin carne', 'Me gusta la comida vegetariana', 'Algo vegetariano estaría bien'], 'responses': ['Una opción deliciosa es una pasta con pesto y espinacas.', 'Podrías hacer un bowl de quinoa con aguacate y garbanzos.', 'Unos tacos vegetarianos con champiñones y queso son perfectos.', '¿Qué tal una ensalada de lentejas con aguacate y tomate?']}]}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Cargar el archivo JSON\n",
        "with open('intents.json', 'r', encoding='utf-8') as file:\n",
        "    intents = json.load(file)\n",
        "\n",
        "# Verificar el contenido del archivo\n",
        "print(intents)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyexODfGszYE"
      },
      "source": [
        "La estructura del archivo JSON `intents` se organiza en forma de un diccionario que contiene una lista de \"intents\". Cada intent es un objeto que incluye tres elementos principales:\n",
        "\n",
        "1. **`tag`**: Una etiqueta que identifica el nombre o categoría del intent. Sirve como identificador único para el intent.\n",
        "\n",
        "2. **`patterns`**: Una lista de frases de ejemplo que representan posibles entradas del usuario. Estas frases son variaciones de lo que el usuario podría decir para expresar ese intent.\n",
        "\n",
        "3. **`responses`**: Una lista de respuestas predefinidas que el chatbot puede utilizar cuando se detecta este intent. El chatbot seleccionará aleatoriamente una de estas respuestas para proporcionar una respuesta coherente al usuario.\n",
        "\n",
        "### Ejemplo de la Estructura de `intents.json`\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"intents\": [\n",
        "    {\n",
        "      \"tag\": \"saludo\",\n",
        "      \"patterns\": [\n",
        "        \"Hola\",\n",
        "        \"Buenos días\",\n",
        "        \"¿Qué tal?\",\n",
        "        \"¿Cómo estás?\",\n",
        "        \"Hola, ¿qué tal?\"\n",
        "      ],\n",
        "      \"responses\": [\n",
        "        \"¡Hola! ¿En qué puedo ayudarte?\",\n",
        "        \"¡Buenos días! ¿Cómo te puedo ayudar?\",\n",
        "        \"Hola, ¿en qué puedo asistirte?\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"despedida\",\n",
        "      \"patterns\": [\n",
        "        \"Adiós\",\n",
        "        \"Hasta luego\",\n",
        "        \"Nos vemos\",\n",
        "        \"Chao\",\n",
        "        \"Me tengo que ir\"\n",
        "      ],\n",
        "      \"responses\": [\n",
        "        \"¡Adiós! Que tengas un buen día.\",\n",
        "        \"Hasta luego, cuídate.\",\n",
        "        \"Nos vemos pronto.\"\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n",
        "En este ejemplo:\n",
        "- Hay dos intents: \"saludo\" y \"despedida\".\n",
        "- Cada intent tiene varias frases de ejemplo en `patterns` que el usuario podría decir.\n",
        "- Las respuestas posibles se encuentran en `responses` y se elige una al azar cuando el intent se detecta.\n",
        "\n",
        "Esta estructura permite que el chatbot reconozca diferentes intents basados en la entrada del usuario y responda adecuadamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xEF2qhMOpXdZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting es-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.7.0/es_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in ./.venv/lib/python3.8/site-packages (from es-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.venv/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./.venv/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.venv/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (56.0.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.venv/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.venv/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in ./.venv/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (24.1)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in ./.venv/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.venv/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.venv/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in ./.venv/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.12.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in ./.venv/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.24.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./.venv/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./.venv/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.66.5)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.venv/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./.venv/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.9.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./.venv/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.8/site-packages (from spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: language-data>=1.2 in ./.venv/lib/python3.8/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in ./.venv/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in ./.venv/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.23.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2023.11.17)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.venv/lib/python3.8/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./.venv/lib/python3.8/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in ./.venv/lib/python3.8/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in ./.venv/lib/python3.8/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (13.9.2)\n",
            "Requirement already satisfied: click>=8.0.0 in ./.venv/lib/python3.8/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in ./.venv/lib/python3.8/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in ./.venv/lib/python3.8/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.8/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in ./.venv/lib/python3.8/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.8/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.8/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: wrapt in ./.venv/lib/python3.8/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->es-core-news-sm==3.7.0) (0.1.2)\n",
            "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download es_core_news_sm\n",
        "import spacy\n",
        "import unidecode\n",
        "from nltk.corpus import stopwords\n",
        "from textblob import TextBlob\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Cargar el modelo de spaCy para español\n",
        "nlp = spacy.load('es_core_news_sm')\n",
        "\n",
        "# Cargar stop words en español\n",
        "stop_words = set(stopwords.words('spanish'))\n",
        "\n",
        "# Función para preprocesar el texto\n",
        "def preprocess_text(text):\n",
        "    # Quitar las tildes y convertir a minúsculas\n",
        "    text = unidecode.unidecode(text.lower())\n",
        "\n",
        "    # Corrección ortográfica usando TextBlob\n",
        "    corrected_text = str(TextBlob(text).correct())\n",
        "\n",
        "    # Tokenizar y lematizar usando spaCy\n",
        "    doc = nlp(corrected_text)\n",
        "\n",
        "    # Filtrar stop words, signos de puntuación y lematizar\n",
        "    processed_words = [\n",
        "        token.lemma_ for token in doc\n",
        "        if token.text not in stop_words and not token.is_punct and not token.is_digit\n",
        "    ]\n",
        "\n",
        "    return ' '.join(processed_words)\n",
        "\n",
        "# Paso 5: Preprocesar los patrones y las etiquetas\n",
        "patterns = []\n",
        "tags = []\n",
        "\n",
        "for intent in intents[\"intents\"]:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        processed_pattern = preprocess_text(pattern)\n",
        "        patterns.append(processed_pattern)\n",
        "        tags.append(intent[\"tag\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LEw2XXVHphr2"
      },
      "outputs": [],
      "source": [
        "# Paso 6: Convertir los patrones en características utilizando CountVectorizer\n",
        "vectorizer = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\n",
        "X = vectorizer.fit_transform(patterns).toarray()\n",
        "\n",
        "# Convertir las etiquetas en números utilizando LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(tags)\n",
        "\n",
        "# Dividir los datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhovUSORtC1l"
      },
      "source": [
        "A continuación, vamos a crear una red neuronal densa para entrenarla utilizando los intents definidos en el archivo JSON. La red neuronal será capaz de aprender a clasificar las entradas del usuario en los diferentes intents, basándose en los ejemplos de frases proporcionados. Este modelo nos permitirá identificar el intent correcto y proporcionar una respuesta adecuada según las respuestas predefinidas asociadas a cada intent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VDAUzmFKpmVE"
      },
      "outputs": [],
      "source": [
        "# Paso 7: Crear el modelo de red neuronal\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(X_train.shape[1],), activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(set(tags)), activation=\"softmax\"))\n",
        "\n",
        "# Compilar el modelo\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOjm8q-xuEyD"
      },
      "source": [
        "### Ejercicio\n",
        "¿Creen que mejorarán las predicciones del chatbot si agregamos una capa recurrente?\n",
        "___\n",
        "Responder acá:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mzIA8Jntpqu7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 1s 17ms/step - loss: 1.9217 - accuracy: 0.2174 - val_loss: 1.9879 - val_accuracy: 0.1667\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.8575 - accuracy: 0.2319 - val_loss: 1.9806 - val_accuracy: 0.1111\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.8057 - accuracy: 0.2899 - val_loss: 1.9690 - val_accuracy: 0.1111\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.7659 - accuracy: 0.3333 - val_loss: 1.9446 - val_accuracy: 0.1111\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.6944 - accuracy: 0.3188 - val_loss: 1.9348 - val_accuracy: 0.1111\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.6910 - accuracy: 0.3043 - val_loss: 1.9351 - val_accuracy: 0.1667\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.5401 - accuracy: 0.4493 - val_loss: 1.9241 - val_accuracy: 0.1667\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.5081 - accuracy: 0.4493 - val_loss: 1.9077 - val_accuracy: 0.2222\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.4447 - accuracy: 0.4928 - val_loss: 1.8910 - val_accuracy: 0.3889\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 1.3428 - accuracy: 0.5072 - val_loss: 1.8355 - val_accuracy: 0.3889\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.3201 - accuracy: 0.5797 - val_loss: 1.7782 - val_accuracy: 0.5556\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.2150 - accuracy: 0.6667 - val_loss: 1.7355 - val_accuracy: 0.5556\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.1351 - accuracy: 0.6377 - val_loss: 1.6953 - val_accuracy: 0.5556\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.0593 - accuracy: 0.7101 - val_loss: 1.6417 - val_accuracy: 0.5556\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.9779 - accuracy: 0.7391 - val_loss: 1.5881 - val_accuracy: 0.6111\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.8564 - accuracy: 0.8116 - val_loss: 1.5463 - val_accuracy: 0.6111\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.8246 - accuracy: 0.7536 - val_loss: 1.5351 - val_accuracy: 0.5556\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.8208 - accuracy: 0.7681 - val_loss: 1.5023 - val_accuracy: 0.5556\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7470 - accuracy: 0.7971 - val_loss: 1.4299 - val_accuracy: 0.6111\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7480 - accuracy: 0.7681 - val_loss: 1.4033 - val_accuracy: 0.6111\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6057 - accuracy: 0.8841 - val_loss: 1.4054 - val_accuracy: 0.5556\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5561 - accuracy: 0.8696 - val_loss: 1.3694 - val_accuracy: 0.5556\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5159 - accuracy: 0.8696 - val_loss: 1.3330 - val_accuracy: 0.5556\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4755 - accuracy: 0.8841 - val_loss: 1.3213 - val_accuracy: 0.6111\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4339 - accuracy: 0.9130 - val_loss: 1.2794 - val_accuracy: 0.6111\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4870 - accuracy: 0.8406 - val_loss: 1.2639 - val_accuracy: 0.6111\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4146 - accuracy: 0.8986 - val_loss: 1.2207 - val_accuracy: 0.6111\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3882 - accuracy: 0.9130 - val_loss: 1.2440 - val_accuracy: 0.6111\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3118 - accuracy: 0.9420 - val_loss: 1.2461 - val_accuracy: 0.5556\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3228 - accuracy: 0.9130 - val_loss: 1.2328 - val_accuracy: 0.6111\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3123 - accuracy: 0.9420 - val_loss: 1.1951 - val_accuracy: 0.6111\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3672 - accuracy: 0.8841 - val_loss: 1.1361 - val_accuracy: 0.6111\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3533 - accuracy: 0.9420 - val_loss: 1.1622 - val_accuracy: 0.6111\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3008 - accuracy: 0.9130 - val_loss: 1.1579 - val_accuracy: 0.6667\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2175 - accuracy: 0.9855 - val_loss: 1.1606 - val_accuracy: 0.6667\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2272 - accuracy: 0.9420 - val_loss: 1.1401 - val_accuracy: 0.7222\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2376 - accuracy: 0.9420 - val_loss: 1.1142 - val_accuracy: 0.7778\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1921 - accuracy: 0.9565 - val_loss: 1.1368 - val_accuracy: 0.7778\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1966 - accuracy: 0.9420 - val_loss: 1.0932 - val_accuracy: 0.7778\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1907 - accuracy: 0.9565 - val_loss: 1.1084 - val_accuracy: 0.7222\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2315 - accuracy: 0.9565 - val_loss: 1.1060 - val_accuracy: 0.7778\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1293 - accuracy: 0.9855 - val_loss: 1.0618 - val_accuracy: 0.7778\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1749 - accuracy: 0.9710 - val_loss: 1.1216 - val_accuracy: 0.7222\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2507 - accuracy: 0.9420 - val_loss: 1.1125 - val_accuracy: 0.7222\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1851 - accuracy: 0.9420 - val_loss: 1.0774 - val_accuracy: 0.7222\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1575 - accuracy: 0.9710 - val_loss: 1.0824 - val_accuracy: 0.6667\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1342 - accuracy: 0.9855 - val_loss: 1.1246 - val_accuracy: 0.7222\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1232 - accuracy: 0.9565 - val_loss: 1.1368 - val_accuracy: 0.7222\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1756 - accuracy: 0.9420 - val_loss: 1.1323 - val_accuracy: 0.7222\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1220 - accuracy: 0.9710 - val_loss: 1.0799 - val_accuracy: 0.6667\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1164 - accuracy: 0.9855 - val_loss: 1.0615 - val_accuracy: 0.6667\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1285 - accuracy: 0.9710 - val_loss: 1.0467 - val_accuracy: 0.7222\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1468 - accuracy: 0.9565 - val_loss: 1.0524 - val_accuracy: 0.6667\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1870 - accuracy: 0.9420 - val_loss: 1.0377 - val_accuracy: 0.7222\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1219 - accuracy: 0.9710 - val_loss: 1.0476 - val_accuracy: 0.7222\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0719 - accuracy: 0.9855 - val_loss: 1.0685 - val_accuracy: 0.7222\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2060 - accuracy: 0.9565 - val_loss: 1.1081 - val_accuracy: 0.7222\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1432 - accuracy: 0.9855 - val_loss: 1.0581 - val_accuracy: 0.8333\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0755 - accuracy: 1.0000 - val_loss: 1.0648 - val_accuracy: 0.7778\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1469 - accuracy: 0.9565 - val_loss: 1.0357 - val_accuracy: 0.7778\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0597 - accuracy: 0.9855 - val_loss: 1.0282 - val_accuracy: 0.7778\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1196 - accuracy: 0.9710 - val_loss: 1.0919 - val_accuracy: 0.7778\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1315 - accuracy: 0.9710 - val_loss: 1.1162 - val_accuracy: 0.7222\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0916 - accuracy: 1.0000 - val_loss: 1.0765 - val_accuracy: 0.7222\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0688 - accuracy: 1.0000 - val_loss: 1.0257 - val_accuracy: 0.7222\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0759 - accuracy: 0.9855 - val_loss: 1.0247 - val_accuracy: 0.7222\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0804 - accuracy: 0.9565 - val_loss: 1.0577 - val_accuracy: 0.7222\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0993 - accuracy: 0.9420 - val_loss: 1.0836 - val_accuracy: 0.7222\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0470 - accuracy: 1.0000 - val_loss: 1.1008 - val_accuracy: 0.7222\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0704 - accuracy: 0.9855 - val_loss: 1.0954 - val_accuracy: 0.7222\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0793 - accuracy: 1.0000 - val_loss: 1.0808 - val_accuracy: 0.7222\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1340 - accuracy: 0.9275 - val_loss: 1.0429 - val_accuracy: 0.7222\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0756 - accuracy: 0.9855 - val_loss: 1.0355 - val_accuracy: 0.7222\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0517 - accuracy: 0.9855 - val_loss: 1.0731 - val_accuracy: 0.7222\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 1.0878 - val_accuracy: 0.7222\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0683 - accuracy: 1.0000 - val_loss: 1.1001 - val_accuracy: 0.7222\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0699 - accuracy: 0.9855 - val_loss: 1.0968 - val_accuracy: 0.7222\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0818 - accuracy: 0.9855 - val_loss: 1.1025 - val_accuracy: 0.7222\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 1.1176 - val_accuracy: 0.7222\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0444 - accuracy: 1.0000 - val_loss: 1.1173 - val_accuracy: 0.7222\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0915 - accuracy: 0.9855 - val_loss: 1.1281 - val_accuracy: 0.7778\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0418 - accuracy: 1.0000 - val_loss: 1.1095 - val_accuracy: 0.7778\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 1.1177 - val_accuracy: 0.7778\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0509 - accuracy: 1.0000 - val_loss: 1.1189 - val_accuracy: 0.7778\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 1.1301 - val_accuracy: 0.7778\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0741 - accuracy: 0.9855 - val_loss: 1.1198 - val_accuracy: 0.7778\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 1.1078 - val_accuracy: 0.7778\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0598 - accuracy: 0.9855 - val_loss: 1.1062 - val_accuracy: 0.7778\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0402 - accuracy: 0.9855 - val_loss: 1.1277 - val_accuracy: 0.7778\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 1.1372 - val_accuracy: 0.7778\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0404 - accuracy: 0.9855 - val_loss: 1.0998 - val_accuracy: 0.7778\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0402 - accuracy: 1.0000 - val_loss: 1.0787 - val_accuracy: 0.7778\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0642 - accuracy: 0.9855 - val_loss: 1.0863 - val_accuracy: 0.7778\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 1.0804 - val_accuracy: 0.7778\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0414 - accuracy: 0.9855 - val_loss: 1.0840 - val_accuracy: 0.7778\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 1.0919 - val_accuracy: 0.7778\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 1.1036 - val_accuracy: 0.7778\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0410 - accuracy: 0.9855 - val_loss: 1.1042 - val_accuracy: 0.7778\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 1.1091 - val_accuracy: 0.7778\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1027 - accuracy: 0.9855 - val_loss: 1.1683 - val_accuracy: 0.7222\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0816 - accuracy: 0.9565 - val_loss: 1.2345 - val_accuracy: 0.7222\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0598 - accuracy: 1.0000 - val_loss: 1.2257 - val_accuracy: 0.7222\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0504 - accuracy: 0.9855 - val_loss: 1.2041 - val_accuracy: 0.7222\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 1.0289 - val_accuracy: 0.7778\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 1.0150 - val_accuracy: 0.7778\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 1.0086 - val_accuracy: 0.7778\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0522 - accuracy: 0.9855 - val_loss: 1.0285 - val_accuracy: 0.7222\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 1.0513 - val_accuracy: 0.7222\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0934 - accuracy: 0.9565 - val_loss: 1.0730 - val_accuracy: 0.7222\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 1.1437 - val_accuracy: 0.7778\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 1.1291 - val_accuracy: 0.7778\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 1.1266 - val_accuracy: 0.7778\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0479 - accuracy: 0.9855 - val_loss: 1.1430 - val_accuracy: 0.7222\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 1.1431 - val_accuracy: 0.7222\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 1.1550 - val_accuracy: 0.7222\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0271 - accuracy: 0.9855 - val_loss: 1.1669 - val_accuracy: 0.7778\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 1.1592 - val_accuracy: 0.7778\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 1.1739 - val_accuracy: 0.7778\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 1.1670 - val_accuracy: 0.7222\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0345 - accuracy: 0.9855 - val_loss: 1.1991 - val_accuracy: 0.7778\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 1.2177 - val_accuracy: 0.7778\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 1.2119 - val_accuracy: 0.7778\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0301 - accuracy: 0.9855 - val_loss: 1.2014 - val_accuracy: 0.7778\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0390 - accuracy: 0.9855 - val_loss: 1.1953 - val_accuracy: 0.7778\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.2072 - val_accuracy: 0.7778\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.1970 - val_accuracy: 0.7778\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 1.2083 - val_accuracy: 0.7778\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.2094 - val_accuracy: 0.7778\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.1909 - val_accuracy: 0.8333\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 1.2120 - val_accuracy: 0.7778\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0584 - accuracy: 0.9855 - val_loss: 1.1631 - val_accuracy: 0.7778\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0273 - accuracy: 0.9855 - val_loss: 1.1435 - val_accuracy: 0.7778\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 1.1435 - val_accuracy: 0.7778\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.1413 - val_accuracy: 0.7778\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.1428 - val_accuracy: 0.7778\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 1.1606 - val_accuracy: 0.7778\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 1.1832 - val_accuracy: 0.7222\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0270 - accuracy: 0.9855 - val_loss: 1.2122 - val_accuracy: 0.7222\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0416 - accuracy: 0.9855 - val_loss: 1.2553 - val_accuracy: 0.7222\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 1.2575 - val_accuracy: 0.7778\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 1.2566 - val_accuracy: 0.7222\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.2369 - val_accuracy: 0.7778\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 1.2432 - val_accuracy: 0.7778\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0506 - accuracy: 0.9855 - val_loss: 1.2196 - val_accuracy: 0.7778\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.1930 - val_accuracy: 0.7778\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 1.2192 - val_accuracy: 0.7778\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0315 - accuracy: 0.9855 - val_loss: 1.2498 - val_accuracy: 0.8333\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0408 - accuracy: 0.9855 - val_loss: 1.2611 - val_accuracy: 0.8333\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.2620 - val_accuracy: 0.8333\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.2677 - val_accuracy: 0.8333\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0296 - accuracy: 0.9855 - val_loss: 1.2797 - val_accuracy: 0.8333\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.2715 - val_accuracy: 0.8333\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0303 - accuracy: 0.9855 - val_loss: 1.2173 - val_accuracy: 0.8333\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 1.2246 - val_accuracy: 0.8333\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0525 - accuracy: 0.9855 - val_loss: 1.3160 - val_accuracy: 0.7778\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0336 - accuracy: 0.9855 - val_loss: 1.3379 - val_accuracy: 0.7222\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.3369 - val_accuracy: 0.7778\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.3510 - val_accuracy: 0.8333\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0650 - accuracy: 0.9855 - val_loss: 1.3270 - val_accuracy: 0.7778\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.2362 - val_accuracy: 0.8333\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 1.2462 - val_accuracy: 0.7222\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.2580 - val_accuracy: 0.7222\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.2915 - val_accuracy: 0.7222\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0360 - accuracy: 0.9855 - val_loss: 1.3074 - val_accuracy: 0.7778\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0213 - accuracy: 0.9855 - val_loss: 1.3024 - val_accuracy: 0.7222\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 1.3449 - val_accuracy: 0.6667\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0351 - accuracy: 0.9855 - val_loss: 1.3713 - val_accuracy: 0.6667\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0253 - accuracy: 0.9855 - val_loss: 1.3901 - val_accuracy: 0.6667\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 1.4086 - val_accuracy: 0.6667\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.4140 - val_accuracy: 0.6667\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.4201 - val_accuracy: 0.6667\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.4319 - val_accuracy: 0.6667\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 1.4370 - val_accuracy: 0.6667\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 1.4143 - val_accuracy: 0.6667\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 1.3411 - val_accuracy: 0.6667\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0220 - accuracy: 0.9855 - val_loss: 1.3135 - val_accuracy: 0.6667\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 1.3486 - val_accuracy: 0.7222\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0426 - accuracy: 0.9855 - val_loss: 1.3885 - val_accuracy: 0.6667\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.3972 - val_accuracy: 0.6667\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 1.4228 - val_accuracy: 0.6667\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.4223 - val_accuracy: 0.6667\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.3991 - val_accuracy: 0.6667\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.3828 - val_accuracy: 0.6667\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0271 - accuracy: 0.9855 - val_loss: 1.3931 - val_accuracy: 0.6667\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.3849 - val_accuracy: 0.6667\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 1.3878 - val_accuracy: 0.6667\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.3995 - val_accuracy: 0.6667\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.4108 - val_accuracy: 0.7222\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.3825 - val_accuracy: 0.7778\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.4051 - val_accuracy: 0.7222\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.4041 - val_accuracy: 0.7222\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.4013 - val_accuracy: 0.7778\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 1.4282 - val_accuracy: 0.7222\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.4499 - val_accuracy: 0.7222\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.4659 - val_accuracy: 0.7222\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.4685 - val_accuracy: 0.7778\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0161 - accuracy: 0.9855 - val_loss: 1.4255 - val_accuracy: 0.7778\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.3960 - val_accuracy: 0.7778\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.4194 - val_accuracy: 0.7778\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.4581 - val_accuracy: 0.7778\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f74ab4bc820>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Entrenar el modelo\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=4, verbose=1, validation_data=(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jV3RHgSjp5GC"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/dandev/repos/project_3/.venv/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# Guardar el modelo y el vectorizador\n",
        "model.save(\"chatbot_model.h5\")\n",
        "np.save(\"classes.npy\", label_encoder.classes_)\n",
        "np.save(\"vectorizer.npy\", vectorizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzO0w0dIsNZy"
      },
      "source": [
        " Los archivos se guardan de forma temporal en la raíz del entorno, es decir, en el directorio principal (`/content/`).\n",
        "\n",
        "En este caso, los archivos se guardarán en:\n",
        "\n",
        "- `/content/chatbot_model.h5`\n",
        "- `/content/classes.npy`\n",
        "- `/content/vectorizer.npy`\n",
        "\n",
        "Tenga en cuenta que es de forma temporal, es decir si se reinicia el entorno estos se borran..\n",
        "\n",
        "#### Cómo Descargar los Archivos Desde Colab\n",
        "\n",
        "Puedes descargar los archivos a tu computadora con las siguientes líneas de código:\n",
        "\n",
        "```python\n",
        "from google.colab import files\n",
        "\n",
        "# Descargar el modelo y los archivos relacionados\n",
        "files.download(\"chatbot_model.h5\")\n",
        "files.download(\"classes.npy\")\n",
        "files.download(\"vectorizer.npy\")\n",
        "```\n",
        "\n",
        "#### Guardar los Archivos en Google Drive\n",
        "\n",
        "También puedes montar tu Google Drive y guardar los archivos allí para que permanezcan disponibles:\n",
        "\n",
        "```python\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Guardar los archivos en una carpeta de Google Drive\n",
        "model.save('/content/drive/MyDrive/chatbot_model.h5')\n",
        "np.save('/content/drive/MyDrive/classes.npy', label_encoder.classes_)\n",
        "np.save('/content/drive/MyDrive/vectorizer.npy', vectorizer)\n",
        "```\n",
        "\n",
        "De esta forma, los archivos se guardarán en tu Google Drive y estarán disponibles incluso después de cerrar la sesión en Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AgiBfVmMp_lg"
      },
      "outputs": [],
      "source": [
        "def chatbot_response(user_input):\n",
        "    # Convertir la entrada del usuario en un formato que el modelo pueda usar\n",
        "    input_data = vectorizer.transform([preprocess_text(user_input)]).toarray()\n",
        "    prediction = model.predict(input_data)\n",
        "\n",
        "    # Obtener la probabilidad más alta y su índice\n",
        "\n",
        "    intent_index = np.argmax(prediction)\n",
        "    max_prob = prediction[0][intent_index]  # Obtener la probabilidad más alta\n",
        "    print(f\"Probabilidad de la predicción: {max_prob:.2f}\")\n",
        "    # Definir un umbral de confianza\n",
        "    confidence_threshold = 0.8  # 70% de confianza\n",
        "\n",
        "    # Si la probabilidad es mayor que el umbral, devolver el intent; si no, pedir que repita la pregunta\n",
        "    if max_prob >= confidence_threshold:\n",
        "        intent_tag = label_encoder.inverse_transform([intent_index])[0]\n",
        "\n",
        "        # Buscar una respuesta aleatoria para el intent predicho\n",
        "        for intent in intents[\"intents\"]:\n",
        "            if intent[\"tag\"] == intent_tag:\n",
        "                response = random.choice(intent[\"responses\"])\n",
        "                break\n",
        "    else:\n",
        "        # Si la confianza es baja, pedir que repita la pregunta\n",
        "        response = \"No estoy seguro de haber entendido. ¿Podrías repetir la pregunta?\"\n",
        "\n",
        "    return response\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3gQF4vgqSTSh"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Bucle de interacción del Chatbot\n",
        "#print(\"¡Hola! Soy un chatbot. ¿En qué puedo ayudarte? (Escribe 'salir' para terminar)\")\n",
        "#while True:\n",
        "#    user_input = input(\"Tú: \")\n",
        "#    if user_input.lower() == \"salir\":\n",
        "#        print(\"Chatbot: ¡Hasta luego!\")\n",
        "#        break\n",
        "#    response = chatbot_response(user_input)\n",
        "#    print(\"Chatbot:\", response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al8R2cb3uVMu"
      },
      "source": [
        "### Ejercicio:\n",
        "Si prueban el chatbot y le preguntan \"¿Qué otra opción hay?\", notarán que no responde de forma correcta. Para solucionar esto, agreguen un nuevo intent en el archivo `intents.json` que maneje este tipo de solicitud, de modo que el chatbot pueda reconocerlo y responder adecuadamente. Agregar que si no entiende (o no encuentra la pregunta) responda \"Repite la pregunta\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nyrg441AIr5z"
      },
      "source": [
        "Como última modificación a nuestro chatbot, vamos a agregarle la opción de que nos pregunte si preferimos una opción vegetariana o con carne cuando estemos buscando recomendaciones de comida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VKccMzT7xHAo"
      },
      "outputs": [],
      "source": [
        "preferencia = None  # Variable global para almacenar la preferencia del usuario\n",
        "ultima_opcion = None  # Variable para recordar el último intent de cena\n",
        "\n",
        "def chatbot_response1(user_input):\n",
        "    global preferencia, ultima_opcion\n",
        "\n",
        "    # Convertir la entrada del usuario en un formato que el modelo pueda usar\n",
        "    input_data = vectorizer.transform([preprocess_text(user_input)]).toarray()\n",
        "    prediction = model.predict(input_data)\n",
        "\n",
        "    # Obtener la probabilidad más alta y su índice\n",
        "    intent_index = np.argmax(prediction)\n",
        "    max_prob = prediction[0][intent_index]  # Obtener la probabilidad más alta\n",
        "    print(f\"Probabilidad de la predicción: {max_prob:.2f}\")\n",
        "\n",
        "    # Definir un umbral de confianza\n",
        "    confidence_threshold = 0.8  # 80% de confianza\n",
        "\n",
        "    # Si la probabilidad es mayor que el umbral, devolver el intent\n",
        "    if max_prob >= confidence_threshold:\n",
        "        intent_tag = label_encoder.inverse_transform([intent_index])[0]\n",
        "\n",
        "        # Si el intent es \"cena\" y aún no tenemos una preferencia, preguntar sobre la preferencia\n",
        "        if intent_tag == \"cena\" and preferencia is None:\n",
        "            preferencia = \"preguntada\"\n",
        "            return \"¿Prefieres una opción con carne o vegetariana?\"\n",
        "\n",
        "        # Si el intent es \"otra_opcion\", ofrecer otra opción basada en la preferencia ya seleccionada\n",
        "        if intent_tag == \"otra_opcion\" and preferencia is not None:\n",
        "            intent_tag = ultima_opcion  # Mantener la última preferencia de cena (carne o vegetariana)\n",
        "\n",
        "        # Si el intent es de despedida o agradecimiento, restablecer la preferencia\n",
        "        if intent_tag in [\"despedida\", \"agradecimiento\"]:\n",
        "            preferencia = None  # Reiniciar la preferencia\n",
        "            for intent in intents[\"intents\"]:\n",
        "                if intent[\"tag\"] == intent_tag:\n",
        "                    response = random.choice(intent[\"responses\"])\n",
        "                    return response\n",
        "\n",
        "    # Si el chatbot ya preguntó sobre las preferencias\n",
        "    if preferencia == \"preguntada\":\n",
        "        if \"carne\" in user_input.lower():\n",
        "            preferencia = \"carne\"\n",
        "            intent_tag = \"cena_carne\"\n",
        "        elif \"vegetariana\" in user_input.lower():\n",
        "            preferencia = \"vegetariana\"\n",
        "            intent_tag = \"cena_vegetariana\"\n",
        "        else:\n",
        "            return \"Lo siento, no entendí tu preferencia. ¿Carne o vegetariana?\"\n",
        "\n",
        "    # Buscar una respuesta aleatoria para el intent predicho\n",
        "    for intent in intents[\"intents\"]:\n",
        "        if intent[\"tag\"] == intent_tag:\n",
        "            response = random.choice(intent[\"responses\"])\n",
        "            break\n",
        "\n",
        "    # Guardar el intent actual como la última opción seleccionada (carne o vegetariana)\n",
        "    if intent_tag in [\"cena_carne\", \"cena_vegetariana\"]:\n",
        "        ultima_opcion = intent_tag  # Mantener la preferencia para \"otra opción\"\n",
        "\n",
        "    return response\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVtz7HzDSLsP"
      },
      "source": [
        "____\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "¡Hola! Soy un chatbot. ¿En qué puedo ayudarte? (Escribe 'salir' para terminar)\n",
            "1/1 [==============================] - 0s 160ms/step\n",
            "Probabilidad de la predicción: 1.00\n",
            "Chatbot: Hola, ¿en qué puedo asistirte?\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Probabilidad de la predicción: 1.00\n",
            "Chatbot: Hola, ¿en qué puedo asistirte?\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Probabilidad de la predicción: 0.52\n",
            "Chatbot: No estoy seguro de haber entendido. ¿Podrías repetir la pregunta?\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "Probabilidad de la predicción: 0.51\n",
            "Chatbot: No estoy seguro de haber entendido. ¿Podrías repetir la pregunta?\n",
            "Chatbot: ¡Hasta luego!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Bucle de interacción del Chatbot\n",
        "print(\"¡Hola! Soy un chatbot. ¿En qué puedo ayudarte? (Escribe 'salir' para terminar)\")\n",
        "while True:\n",
        "    user_input = input(\"Tú: \")\n",
        "    if user_input.lower() == \"salir\":\n",
        "        print(\"Chatbot: ¡Hasta luego!\")\n",
        "        break\n",
        "    response = chatbot_response(user_input)\n",
        "    print(\"Chatbot:\", response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "history_visible": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
