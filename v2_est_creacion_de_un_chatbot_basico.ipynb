{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OL9isTPfrOY_"
      },
      "source": [
        "# Chatbot para que me proponga que cenar\n",
        "\n",
        "\n",
        "## Introducción\n",
        "\n",
        "En este proyecto, se propone desarrollar un chatbot basado en el uso de una red neuronal para clasificar intents. El objetivo principal es crear un asistente conversacional capaz de interactuar con los usuarios y responder a sus solicitudes de manera adecuada. Para lograr esto, se utilizará un enfoque basado en machine learning, específicamente una red neuronal alimentada con un conjunto de datos etiquetados que describen diversos intents y patrones de conversación.\n",
        "\n",
        "El chatbot se entrenará utilizando un archivo de configuración en formato JSON, que contiene un diccionario de intents. Cada intent incluye un conjunto de frases de ejemplo que representan las posibles entradas del usuario, así como una lista de respuestas predefinidas que el chatbot proporcionará al identificar dicho intent. Estos datos serán preprocesados y convertidos en una representación numérica que permita a la red neuronal aprender a clasificar correctamente los intents en función de las entradas del usuario.\n",
        "\n",
        "El modelo entrenado será capaz de identificar el intent del usuario a partir de su mensaje y seleccionar una respuesta adecuada de las respuestas predefinidas asociadas.\n",
        "\n",
        "El enfoque basado en el uso de redes neuronales para la clasificación de intents permite que el chatbot sea adaptable y escalable. A medida que se agreguen más intents o se modifiquen los existentes, el modelo se puede volver a entrenar para mejorar la precisión y la variedad de respuestas, proporcionando una experiencia más enriquecedora al usuario.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mZ5xF8uZpB7O"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/dandev/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /home/dandev/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /home/dandev/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GeTuYdZI3x0y"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to nltk_data/...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to nltk_data/...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "nltk.download('stopwords', download_dir='nltk_data/')\n",
        "nltk.download('punkt', download_dir='nltk_data/')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "clhk_IT0nYqT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-15 21:03:04.171669: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-10-15 21:03:04.223864: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-10-15 21:03:04.225570: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-10-15 21:03:05.038362: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import tensorflow as tf\n",
        "import unidecode\n",
        "\n",
        "# Importar bibliotecas necesarias\n",
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import unidecode\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Kb3BvlLcnmZO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'intents': [{'tag': 'saludo', 'patterns': ['Hola', 'Buenos días', '¿Qué tal?', '¿Cómo estás?', 'Hola, ¿qué tal?', '¡Hola!', 'Buenas', 'Hola, ¿cómo te va?', 'Saludos', 'Hola, ¿cómo te encuentras?', '¿Qué hay de nuevo?', 'Hola, mucho gusto', 'Buenas tardes', 'Hola, buen día', '¿Qué cuentas?'], 'responses': ['¡Hola! ¿En qué puedo ayudarte?', '¡Buenos días! ¿Cómo te puedo ayudar?', 'Hola, ¿en qué puedo asistirte?']}, {'tag': 'despedida', 'patterns': ['Adiós', 'Hasta luego', 'Nos vemos', 'Chao', 'Me tengo que ir', 'Hasta pronto', 'Cuídate', 'Nos vemos luego', 'Me voy', 'Que tengas un buen día', 'Hasta la próxima', 'Nos vemos más tarde', 'Adiós, que estés bien', 'Me despido', 'Que te vaya bien'], 'responses': ['¡Adiós! Que tengas un buen día.', 'Hasta luego, cuídate.', 'Nos vemos pronto.']}, {'tag': 'opcion', 'patterns': ['opción', 'Tienes otra opción', 'No me gusta tu sugerencia', 'otra cosa', 'tienes otra comida', '¿Qué otra opción hay?', '¿Puedes darme otra opción?', 'Dame otra sugerencia', 'No estoy convencido, otra opción', '¿Qué más tienes?', 'Otra alternativa, por favor', 'No me gusta, ¿qué más puedes ofrecer?', 'Sugiéreme otra cosa', '¿Alguna otra recomendación?', 'Algo más, por favor', 'Quiero una alternativa'], 'responses': ['Otra opción podría ser preparar tacos vegetarianos con frijoles y aguacate.', '¿Qué tal una sopa de tomate y albahaca con un toque de crema?', 'También podrías probar un risotto de setas y parmesano.', 'Una tortilla de patatas con cebolla caramelizada podría ser una opción interesante.', 'Ensalada César con pollo a la parrilla.', 'Sándwich de pavo con queso suizo y mostaza.', 'Pizza de verduras asadas con queso de cabra.', 'Sopa de calabaza y zanahoria con pan crujiente.', 'Pasta con salsa de champiñones y espinacas.', 'Tortitas de garbanzos con ensalada de rúcula.', 'Papas rellenas con brócoli y queso cheddar.', 'Enchiladas de pollo con salsa verde.', 'Bowl de quinoa con hummus y vegetales asados.', 'Curry de garbanzos y espinacas con arroz basmati.']}, {'tag': 'agradecimiento', 'patterns': ['Gracias', 'Muchas gracias', 'Te lo agradezco', 'Gracias por la ayuda', 'Buena opción', 'Me gusta esa opción', 'Esa opción suena bien', 'Suena delicioso', 'Qué buena sugerencia', 'Me encanta esa idea', 'Esa opción está genial', 'Gracias, suena muy bien', 'Qué buena opción para cenar', 'Parece delicioso', 'Me encanta la sugerencia'], 'responses': ['¡De nada! Siempre estoy aquí para ayudarte.', 'Es un placer ayudarte.', '¡Con gusto!']}, {'tag': 'cena', 'patterns': ['¿Qué podría cenar hoy?', '¿Tienes alguna sugerencia para la cena?', 'Estoy buscando ideas para cenar', 'Quiero preparar algo para cenar', 'No sé qué cenar hoy', '¿Qué me recomiendas para cenar?', '¿Qué puedo cocinar esta noche?', 'Dame una idea para la cena', 'Estoy pensando en qué cenar', 'Sugiéreme algo para la cena', '¿Tienes alguna idea para la cena?', 'No sé qué hacer de cenar', '¿Qué podría cocinar esta noche?', 'Necesito ideas para la cena', '¿Alguna recomendación para cenar?', '¿Qué comer hoy?', 'Tengo hambre y no sé qué comer', 'que opcion de cena me podrias dar?'], 'responses': ['Ensalada de pollo con aguacate y aderezo de mostaza.', 'Lasaña de verduras con queso ricotta.', 'Filete de atún a la parrilla con espárragos.', 'Sopa de lentejas con pan integral tostado.', 'Wraps de pollo al pesto con vegetales asados.', 'Arroz con mariscos y un toque de limón.', 'Quiche de espinacas y queso feta.', 'Hamburguesa de garbanzos con guacamole.', 'Tacos de pescado con col y salsa de mango.', 'Pechuga de pollo a la plancha con puré de batata.']}, {'tag': 'cena_carne', 'patterns': ['Quiero una opción con carne', 'Prefiero carne', 'Me gusta la carne', 'Algo con carne estaría bien'], 'responses': ['Podrías preparar un filete de res con puré de papas.', '¿Qué tal un pollo a la parrilla con ensalada?', 'Unos tacos de carne asada siempre son una buena opción.', 'Podrías hacer unas albóndigas con salsa de tomate.']}, {'tag': 'cena_vegetariana', 'patterns': ['Quiero una opción vegetariana', 'Prefiero algo sin carne', 'Me gusta la comida vegetariana', 'Algo vegetariano estaría bien'], 'responses': ['Una opción deliciosa es una pasta con pesto y espinacas.', 'Podrías hacer un bowl de quinoa con aguacate y garbanzos.', 'Unos tacos vegetarianos con champiñones y queso son perfectos.', '¿Qué tal una ensalada de lentejas con aguacate y tomate?']}]}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# Cargar el archivo JSON\n",
        "with open('intents.json', 'r', encoding='utf-8') as file:\n",
        "    intents = json.load(file)\n",
        "\n",
        "# Verificar el contenido del archivo\n",
        "print(intents)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyexODfGszYE"
      },
      "source": [
        "La estructura del archivo JSON `intents` se organiza en forma de un diccionario que contiene una lista de \"intents\". Cada intent es un objeto que incluye tres elementos principales:\n",
        "\n",
        "1. **`tag`**: Una etiqueta que identifica el nombre o categoría del intent. Sirve como identificador único para el intent.\n",
        "\n",
        "2. **`patterns`**: Una lista de frases de ejemplo que representan posibles entradas del usuario. Estas frases son variaciones de lo que el usuario podría decir para expresar ese intent.\n",
        "\n",
        "3. **`responses`**: Una lista de respuestas predefinidas que el chatbot puede utilizar cuando se detecta este intent. El chatbot seleccionará aleatoriamente una de estas respuestas para proporcionar una respuesta coherente al usuario.\n",
        "\n",
        "### Ejemplo de la Estructura de `intents.json`\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"intents\": [\n",
        "    {\n",
        "      \"tag\": \"saludo\",\n",
        "      \"patterns\": [\n",
        "        \"Hola\",\n",
        "        \"Buenos días\",\n",
        "        \"¿Qué tal?\",\n",
        "        \"¿Cómo estás?\",\n",
        "        \"Hola, ¿qué tal?\"\n",
        "      ],\n",
        "      \"responses\": [\n",
        "        \"¡Hola! ¿En qué puedo ayudarte?\",\n",
        "        \"¡Buenos días! ¿Cómo te puedo ayudar?\",\n",
        "        \"Hola, ¿en qué puedo asistirte?\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"tag\": \"despedida\",\n",
        "      \"patterns\": [\n",
        "        \"Adiós\",\n",
        "        \"Hasta luego\",\n",
        "        \"Nos vemos\",\n",
        "        \"Chao\",\n",
        "        \"Me tengo que ir\"\n",
        "      ],\n",
        "      \"responses\": [\n",
        "        \"¡Adiós! Que tengas un buen día.\",\n",
        "        \"Hasta luego, cuídate.\",\n",
        "        \"Nos vemos pronto.\"\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n",
        "\n",
        "En este ejemplo:\n",
        "- Hay dos intents: \"saludo\" y \"despedida\".\n",
        "- Cada intent tiene varias frases de ejemplo en `patterns` que el usuario podría decir.\n",
        "- Las respuestas posibles se encuentran en `responses` y se elige una al azar cuando el intent se detecta.\n",
        "\n",
        "Esta estructura permite que el chatbot reconozca diferentes intents basados en la entrada del usuario y responda adecuadamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xEF2qhMOpXdZ"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'spacy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01munidecode\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "import unidecode\n",
        "from nltk.corpus import stopwords\n",
        "from textblob import TextBlob\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Cargar el modelo de spaCy para español\n",
        "nlp = spacy.load('es_core_news_sm')\n",
        "\n",
        "# Cargar stop words en español\n",
        "stop_words = set(stopwords.words('spanish'))\n",
        "\n",
        "# Función para preprocesar el texto\n",
        "def preprocess_text(text):\n",
        "    # Quitar las tildes y convertir a minúsculas\n",
        "    text = unidecode.unidecode(text.lower())\n",
        "\n",
        "    # Corrección ortográfica usando TextBlob\n",
        "    corrected_text = str(TextBlob(text).correct())\n",
        "\n",
        "    # Tokenizar y lematizar usando spaCy\n",
        "    doc = nlp(corrected_text)\n",
        "\n",
        "    # Filtrar stop words, signos de puntuación y lematizar\n",
        "    processed_words = [\n",
        "        token.lemma_ for token in doc\n",
        "        if token.text not in stop_words and not token.is_punct and not token.is_digit\n",
        "    ]\n",
        "\n",
        "    return ' '.join(processed_words)\n",
        "\n",
        "# Paso 5: Preprocesar los patrones y las etiquetas\n",
        "patterns = []\n",
        "tags = []\n",
        "\n",
        "for intent in intents[\"intents\"]:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        processed_pattern = preprocess_text(pattern)\n",
        "        patterns.append(processed_pattern)\n",
        "        tags.append(intent[\"tag\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEw2XXVHphr2"
      },
      "outputs": [],
      "source": [
        "# Paso 6: Convertir los patrones en características utilizando CountVectorizer\n",
        "vectorizer = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")\n",
        "X = vectorizer.fit_transform(patterns).toarray()\n",
        "\n",
        "# Convertir las etiquetas en números utilizando LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(tags)\n",
        "\n",
        "# Dividir los datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhovUSORtC1l"
      },
      "source": [
        "A continuación, vamos a crear una red neuronal densa para entrenarla utilizando los intents definidos en el archivo JSON. La red neuronal será capaz de aprender a clasificar las entradas del usuario en los diferentes intents, basándose en los ejemplos de frases proporcionados. Este modelo nos permitirá identificar el intent correcto y proporcionar una respuesta adecuada según las respuestas predefinidas asociadas a cada intent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDAUzmFKpmVE"
      },
      "outputs": [],
      "source": [
        "# Paso 7: Crear el modelo de red neuronal\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(X_train.shape[1],), activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(set(tags)), activation=\"softmax\"))\n",
        "\n",
        "# Compilar el modelo\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOjm8q-xuEyD"
      },
      "source": [
        "### Ejercicio\n",
        "¿Creen que mejorarán las predicciones del chatbot si agregamos una capa recurrente?\n",
        "___\n",
        "Responder acá:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzIA8Jntpqu7"
      },
      "outputs": [],
      "source": [
        "# Entrenar el modelo\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=4, verbose=1, validation_data=(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jV3RHgSjp5GC"
      },
      "outputs": [],
      "source": [
        "# Guardar el modelo y el vectorizador\n",
        "model.save(\"chatbot_model.h5\")\n",
        "np.save(\"classes.npy\", label_encoder.classes_)\n",
        "np.save(\"vectorizer.npy\", vectorizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzO0w0dIsNZy"
      },
      "source": [
        " Los archivos se guardan de forma temporal en la raíz del entorno, es decir, en el directorio principal (`/content/`).\n",
        "\n",
        "En este caso, los archivos se guardarán en:\n",
        "\n",
        "- `/content/chatbot_model.h5`\n",
        "- `/content/classes.npy`\n",
        "- `/content/vectorizer.npy`\n",
        "\n",
        "Tenga en cuenta que es de forma temporal, es decir si se reinicia el entorno estos se borran..\n",
        "\n",
        "#### Cómo Descargar los Archivos Desde Colab\n",
        "\n",
        "Puedes descargar los archivos a tu computadora con las siguientes líneas de código:\n",
        "\n",
        "```python\n",
        "from google.colab import files\n",
        "\n",
        "# Descargar el modelo y los archivos relacionados\n",
        "files.download(\"chatbot_model.h5\")\n",
        "files.download(\"classes.npy\")\n",
        "files.download(\"vectorizer.npy\")\n",
        "```\n",
        "\n",
        "#### Guardar los Archivos en Google Drive\n",
        "\n",
        "También puedes montar tu Google Drive y guardar los archivos allí para que permanezcan disponibles:\n",
        "\n",
        "```python\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Guardar los archivos en una carpeta de Google Drive\n",
        "model.save('/content/drive/MyDrive/chatbot_model.h5')\n",
        "np.save('/content/drive/MyDrive/classes.npy', label_encoder.classes_)\n",
        "np.save('/content/drive/MyDrive/vectorizer.npy', vectorizer)\n",
        "```\n",
        "\n",
        "De esta forma, los archivos se guardarán en tu Google Drive y estarán disponibles incluso después de cerrar la sesión en Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgiBfVmMp_lg"
      },
      "outputs": [],
      "source": [
        "def chatbot_response(user_input):\n",
        "    # Convertir la entrada del usuario en un formato que el modelo pueda usar\n",
        "    input_data = vectorizer.transform([preprocess_text(user_input)]).toarray()\n",
        "    prediction = model.predict(input_data)\n",
        "\n",
        "    # Obtener la probabilidad más alta y su índice\n",
        "\n",
        "    intent_index = np.argmax(prediction)\n",
        "    max_prob = prediction[0][intent_index]  # Obtener la probabilidad más alta\n",
        "    print(f\"Probabilidad de la predicción: {max_prob:.2f}\")\n",
        "    # Definir un umbral de confianza\n",
        "    confidence_threshold = 0.8  # 70% de confianza\n",
        "\n",
        "    # Si la probabilidad es mayor que el umbral, devolver el intent; si no, pedir que repita la pregunta\n",
        "    if max_prob >= confidence_threshold:\n",
        "        intent_tag = label_encoder.inverse_transform([intent_index])[0]\n",
        "\n",
        "        # Buscar una respuesta aleatoria para el intent predicho\n",
        "        for intent in intents[\"intents\"]:\n",
        "            if intent[\"tag\"] == intent_tag:\n",
        "                response = random.choice(intent[\"responses\"])\n",
        "                break\n",
        "    else:\n",
        "        # Si la confianza es baja, pedir que repita la pregunta\n",
        "        response = \"No estoy seguro de haber entendido. ¿Podrías repetir la pregunta?\"\n",
        "\n",
        "    return response\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gQF4vgqSTSh"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Bucle de interacción del Chatbot\n",
        "print(\"¡Hola! Soy un chatbot. ¿En qué puedo ayudarte? (Escribe 'salir' para terminar)\")\n",
        "while True:\n",
        "    user_input = input(\"Tú: \")\n",
        "    if user_input.lower() == \"salir\":\n",
        "        print(\"Chatbot: ¡Hasta luego!\")\n",
        "        break\n",
        "    response = chatbot_response(user_input)\n",
        "    print(\"Chatbot:\", response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al8R2cb3uVMu"
      },
      "source": [
        "### Ejercicio:\n",
        "Si prueban el chatbot y le preguntan \"¿Qué otra opción hay?\", notarán que no responde de forma correcta. Para solucionar esto, agreguen un nuevo intent en el archivo `intents.json` que maneje este tipo de solicitud, de modo que el chatbot pueda reconocerlo y responder adecuadamente. Agregar que si no entiende (o no encuentra la pregunta) responda \"Repite la pregunta\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nyrg441AIr5z"
      },
      "source": [
        "Como última modificación a nuestro chatbot, vamos a agregarle la opción de que nos pregunte si preferimos una opción vegetariana o con carne cuando estemos buscando recomendaciones de comida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKccMzT7xHAo"
      },
      "outputs": [],
      "source": [
        "preferencia = None  # Variable global para almacenar la preferencia del usuario\n",
        "ultima_opcion = None  # Variable para recordar el último intent de cena\n",
        "\n",
        "def chatbot_response1(user_input):\n",
        "    global preferencia, ultima_opcion\n",
        "\n",
        "    # Convertir la entrada del usuario en un formato que el modelo pueda usar\n",
        "    input_data = vectorizer.transform([preprocess_text(user_input)]).toarray()\n",
        "    prediction = model.predict(input_data)\n",
        "\n",
        "    # Obtener la probabilidad más alta y su índice\n",
        "    intent_index = np.argmax(prediction)\n",
        "    max_prob = prediction[0][intent_index]  # Obtener la probabilidad más alta\n",
        "    print(f\"Probabilidad de la predicción: {max_prob:.2f}\")\n",
        "\n",
        "    # Definir un umbral de confianza\n",
        "    confidence_threshold = 0.8  # 80% de confianza\n",
        "\n",
        "    # Si la probabilidad es mayor que el umbral, devolver el intent\n",
        "    if max_prob >= confidence_threshold:\n",
        "        intent_tag = label_encoder.inverse_transform([intent_index])[0]\n",
        "\n",
        "        # Si el intent es \"cena\" y aún no tenemos una preferencia, preguntar sobre la preferencia\n",
        "        if intent_tag == \"cena\" and preferencia is None:\n",
        "            preferencia = \"preguntada\"\n",
        "            return \"¿Prefieres una opción con carne o vegetariana?\"\n",
        "\n",
        "        # Si el intent es \"otra_opcion\", ofrecer otra opción basada en la preferencia ya seleccionada\n",
        "        if intent_tag == \"otra_opcion\" and preferencia is not None:\n",
        "            intent_tag = ultima_opcion  # Mantener la última preferencia de cena (carne o vegetariana)\n",
        "\n",
        "        # Si el intent es de despedida o agradecimiento, restablecer la preferencia\n",
        "        if intent_tag in [\"despedida\", \"agradecimiento\"]:\n",
        "            preferencia = None  # Reiniciar la preferencia\n",
        "            for intent in intents[\"intents\"]:\n",
        "                if intent[\"tag\"] == intent_tag:\n",
        "                    response = random.choice(intent[\"responses\"])\n",
        "                    return response\n",
        "\n",
        "    # Si el chatbot ya preguntó sobre las preferencias\n",
        "    if preferencia == \"preguntada\":\n",
        "        if \"carne\" in user_input.lower():\n",
        "            preferencia = \"carne\"\n",
        "            intent_tag = \"cena_carne\"\n",
        "        elif \"vegetariana\" in user_input.lower():\n",
        "            preferencia = \"vegetariana\"\n",
        "            intent_tag = \"cena_vegetariana\"\n",
        "        else:\n",
        "            return \"Lo siento, no entendí tu preferencia. ¿Carne o vegetariana?\"\n",
        "\n",
        "    # Buscar una respuesta aleatoria para el intent predicho\n",
        "    for intent in intents[\"intents\"]:\n",
        "        if intent[\"tag\"] == intent_tag:\n",
        "            response = random.choice(intent[\"responses\"])\n",
        "            break\n",
        "\n",
        "    # Guardar el intent actual como la última opción seleccionada (carne o vegetariana)\n",
        "    if intent_tag in [\"cena_carne\", \"cena_vegetariana\"]:\n",
        "        ultima_opcion = intent_tag  # Mantener la preferencia para \"otra opción\"\n",
        "\n",
        "    return response\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gu48ltPOxM4o"
      },
      "outputs": [],
      "source": [
        "print(\"¡Hola! Soy un chatbot con memoria. ¿En qué puedo ayudarte? (Escribe 'salir' para terminar)\")\n",
        "while True:\n",
        "    user_input = input(\"Tú: \")\n",
        "    if user_input.lower() == \"salir\":\n",
        "        print(\"Chatbot: ¡Hasta luego!\")\n",
        "        break\n",
        "    response = chatbot_response1(user_input)\n",
        "    print(\"Chatbot:\", response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "Y7FawJVNkllO",
        "outputId": "be1715c7-c288-4cf3-aca5-cd1673615ef2"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(\"chatbot_model.h5\")\n",
        "files.download(\"classes.npy\")\n",
        "files.download(\"vectorizer.npy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVtz7HzDSLsP"
      },
      "source": [
        "____\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "history_visible": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
